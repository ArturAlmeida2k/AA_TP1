{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📥 Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 13:47:38.164692: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-22 13:47:42.072672: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtreino\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StratifiedShuffleSplit\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "File \u001b[0;32m~/Desktop/mestrado/AA/AA_TP1/treino.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Importações para a rede neural\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/__init__.py:36\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py:26\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m self_check\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mself_check\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreload_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m   \u001b[38;5;66;03m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[1;32m     32\u001b[0m   \u001b[38;5;66;03m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/platform/self_check.py:63\u001b[0m, in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find the DLL(s) \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m. TensorFlow requires that these DLLs \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe installed in a directory that is named in your \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m           \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing))\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;66;03m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[1;32m     60\u001b[0m   \u001b[38;5;66;03m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;66;03m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;66;03m# SIGILL).\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_cpu_feature_guard\n\u001b[1;32m     64\u001b[0m   _pywrap_cpu_feature_guard\u001b[38;5;241m.\u001b[39mInfoAboutUnusedCPUFeatures()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import data\n",
    "import treino\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn import metrics #accuracy measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Carregar e Inspecionar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Carregar os dados\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/bank.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#df = pd.read_csv('/home/rafa/Secretária/AA/AA_TP1/Data/bank.csv')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Exibir as primeiras linhas\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Carregar os dados\n",
    "df = pd.read_csv('Data/bank.csv')\n",
    "#df = pd.read_csv('/home/rafa/Secretária/AA/AA_TP1/Data/bank.csv')\n",
    "\n",
    "# Exibir as primeiras linhas\n",
    "print(df.head())\n",
    "\n",
    "# Verificar valores ausentes\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Estatísticas básicas\n",
    "print(df.describe())\n",
    "\n",
    "# Distribuição da variável alvo\n",
    "print(df['deposit'].value_counts())\n",
    "\n",
    "# Tipos de dados\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Visualização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ordenar os meses antes de exibir\n",
    "ordem_meses = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "df['month'] = pd.Categorical(df['month'], categories=ordem_meses, ordered=True)\n",
    "\n",
    "# Gráfico de barras para depósitos por profissão\n",
    "plt.figure(figsize=(20, 10))\n",
    "df.groupby(['job', 'deposit']).size().unstack().plot(\n",
    "    kind='bar',\n",
    "    stacked=False,\n",
    "    ax=plt.gca(),\n",
    "    color=['lightcoral', 'lightgreen'],\n",
    "    edgecolor='black'\n",
    ")\n",
    "plt.title('Distribuição dos Depósitos por Profissão')\n",
    "plt.xlabel('Profissão')\n",
    "plt.ylabel('Contagem')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "i = 0\n",
    "for col in df.columns:\n",
    "    if (df[col].dtype == 'object' and col not in ['deposit', 'job']) or col == 'month':  \n",
    "        i += 1  \n",
    "        plt.subplot(4, 2, i)\n",
    "        df.groupby([col, 'deposit']).size().unstack().plot(\n",
    "            kind='bar', \n",
    "            stacked=False, \n",
    "            ax=plt.gca(),\n",
    "            color=['lightcoral','lightgreen'],\n",
    "            edgecolor='black')\n",
    "        plt.title(f'Distribuição de Depósitos por {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Contagem')\n",
    "        plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(20,10))\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'int64':\n",
    "        i += 1\n",
    "        plt.subplot(4, 2, i)\n",
    "\n",
    "        yes_data = df[df['deposit'] == 'yes'][col]\n",
    "        no_data = df[df['deposit'] == 'no'][col]\n",
    "        total_data = df[col]\n",
    "        data_to_plot = [yes_data, no_data, total_data]\n",
    "        colors = ['lightgreen', 'lightcoral', 'lightblue']\n",
    "        boxprops = [dict(facecolor=color, color='blue') for color in colors]\n",
    "\n",
    "        bp = plt.boxplot(data_to_plot, labels=['Yes', 'No', 'Total'], patch_artist=True, \n",
    "                vert=False,\n",
    "                medianprops=dict(color='red'),\n",
    "                whiskerprops=dict(color='blue'),\n",
    "                capprops=dict(color='blue'),\n",
    "                flierprops=dict(markerfacecolor='blue', marker='o', markersize=5, linestyle='none'))\n",
    "\n",
    "        for patch, color in zip(bp['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "\n",
    "        plt.title(f'BoxPlot de {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧹 Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar pré-processamento\n",
    "df = data.preposessing(df)\n",
    "\n",
    "# print(df)\n",
    "# print(df.describe())\n",
    "# df.to_csv('AA_TP1/Data/bank_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✂️ Divisão dos Dados em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporção no conjunto de treino:\n",
      "deposit\n",
      "0    0.526151\n",
      "1    0.473849\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Proporção no conjunto de teste:\n",
      "deposit\n",
      "0    0.526198\n",
      "1    0.473802\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Criar divisão estratificada dos dados\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=5)\n",
    "\n",
    "for train_index, test_index in split.split(df, df['deposit']):\n",
    "    train = df.loc[train_index]\n",
    "    test = df.loc[test_index]\n",
    "\n",
    "# Exibir a proporção dos depósitos em cada conjunto\n",
    "print(\"Proporção no conjunto de treino:\")\n",
    "print(train['deposit'].value_counts() / train.shape[0])\n",
    "\n",
    "print(\"\\nProporção no conjunto de teste:\")\n",
    "print(test['deposit'].value_counts() / test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎯 Separação de Features (`X`) e Rótulo (`y`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features e rótulo no treino\n",
    "X_train = train.drop(columns=['deposit'])\n",
    "y_train = train['deposit']\n",
    "\n",
    "# Separar features e rótulo no teste\n",
    "X_test = test.drop(columns=['deposit'])\n",
    "y_test = test['deposit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📏 Normalização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o normalizador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar e transformar os dados\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "Época 0: Loss = 1.3142\n",
      "Época 100: Loss = 0.7777\n",
      "Época 200: Loss = 0.7314\n",
      "Época 300: Loss = 0.7148\n",
      "Época 400: Loss = 0.7008\n",
      "Época 500: Loss = 0.6883\n",
      "Época 600: Loss = 0.6770\n",
      "Época 700: Loss = 0.6665\n",
      "Época 800: Loss = 0.6567\n",
      "Época 900: Loss = 0.6475\n",
      "Época 1000: Loss = 0.6386\n",
      "Época 1100: Loss = 0.6302\n",
      "Época 1200: Loss = 0.6221\n",
      "Época 1300: Loss = 0.6143\n",
      "Época 1400: Loss = 0.6067\n",
      "Época 1500: Loss = 0.5993\n",
      "Época 1600: Loss = 0.5922\n",
      "Época 1700: Loss = 0.5854\n",
      "Época 1800: Loss = 0.5788\n",
      "Época 1900: Loss = 0.5724\n",
      "Época 2000: Loss = 0.5663\n",
      "Época 2100: Loss = 0.5604\n",
      "Época 2200: Loss = 0.5548\n",
      "Época 2300: Loss = 0.5494\n",
      "Época 2400: Loss = 0.5443\n",
      "Época 2500: Loss = 0.5394\n",
      "Época 2600: Loss = 0.5348\n",
      "Época 2700: Loss = 0.5304\n",
      "Época 2800: Loss = 0.5262\n",
      "Época 2900: Loss = 0.5222\n",
      "Época 3000: Loss = 0.5185\n",
      "Época 3100: Loss = 0.5149\n",
      "Época 3200: Loss = 0.5116\n",
      "Época 3300: Loss = 0.5084\n",
      "Época 3400: Loss = 0.5054\n",
      "Época 3500: Loss = 0.5026\n",
      "Época 3600: Loss = 0.4999\n",
      "Época 3700: Loss = 0.4973\n",
      "Época 3800: Loss = 0.4949\n",
      "Época 3900: Loss = 0.4927\n",
      "Época 4000: Loss = 0.4905\n",
      "Época 4100: Loss = 0.4885\n",
      "Época 4200: Loss = 0.4866\n",
      "Época 4300: Loss = 0.4848\n",
      "Época 4400: Loss = 0.4830\n",
      "Época 4500: Loss = 0.4814\n",
      "Época 4600: Loss = 0.4799\n",
      "Época 4700: Loss = 0.4784\n",
      "Época 4800: Loss = 0.4770\n",
      "Época 4900: Loss = 0.4757\n",
      "Época 5000: Loss = 0.4744\n",
      "Época 5100: Loss = 0.4733\n",
      "Época 5200: Loss = 0.4721\n",
      "Época 5300: Loss = 0.4711\n",
      "Época 5400: Loss = 0.4701\n",
      "Época 5500: Loss = 0.4691\n",
      "Época 5600: Loss = 0.4682\n",
      "Época 5700: Loss = 0.4673\n",
      "Época 5800: Loss = 0.4665\n",
      "Época 5900: Loss = 0.4657\n",
      "Época 6000: Loss = 0.4649\n",
      "Época 6100: Loss = 0.4642\n",
      "Época 6200: Loss = 0.4635\n",
      "Época 6300: Loss = 0.4629\n",
      "Época 6400: Loss = 0.4622\n",
      "Época 6500: Loss = 0.4616\n",
      "Época 6600: Loss = 0.4611\n",
      "Época 6700: Loss = 0.4605\n",
      "Época 6800: Loss = 0.4600\n",
      "Época 6900: Loss = 0.4595\n",
      "Época 7000: Loss = 0.4590\n",
      "Época 7100: Loss = 0.4586\n",
      "Época 7200: Loss = 0.4581\n",
      "Época 7300: Loss = 0.4577\n",
      "Época 7400: Loss = 0.4573\n",
      "Época 7500: Loss = 0.4569\n",
      "Época 7600: Loss = 0.4565\n",
      "Época 7700: Loss = 0.4562\n",
      "Época 7800: Loss = 0.4558\n",
      "Época 7900: Loss = 0.4555\n",
      "Época 8000: Loss = 0.4552\n",
      "Época 8100: Loss = 0.4549\n",
      "Época 8200: Loss = 0.4546\n",
      "Época 8300: Loss = 0.4543\n",
      "Época 8400: Loss = 0.4540\n",
      "Época 8500: Loss = 0.4537\n",
      "Época 8600: Loss = 0.4535\n",
      "Época 8700: Loss = 0.4532\n",
      "Época 8800: Loss = 0.4530\n",
      "Época 8900: Loss = 0.4527\n",
      "Época 9000: Loss = 0.4525\n",
      "Época 9100: Loss = 0.4523\n",
      "Época 9200: Loss = 0.4521\n",
      "Época 9300: Loss = 0.4518\n",
      "Época 9400: Loss = 0.4516\n",
      "Época 9500: Loss = 0.4514\n",
      "Época 9600: Loss = 0.4512\n",
      "Época 9700: Loss = 0.4510\n",
      "Época 9800: Loss = 0.4509\n",
      "Época 9900: Loss = 0.4507\n",
      "Acurácia da rede neural: 79.58%\n"
     ]
    }
   ],
   "source": [
    "# Chamar função de treino da rede neural\n",
    "treino.rede_neural2(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
